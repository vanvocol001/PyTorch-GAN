{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets, transforms\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_grid, save_image\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTML, display\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "# !pip install torch torchvision matplotlib tqdm\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from IPython.display import HTML, display\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Image Folder Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"progress_images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 64\n",
    "lr = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "latent_dim = 100\n",
    "img_size = 64\n",
    "channels = 3\n",
    "sample_interval = 500\n",
    "\n",
    "img_shape = (channels, img_size, img_size)\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *img_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Define Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.CenterCrop(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*channels, [0.5]*channels)\n",
    "])\n",
    "\n",
    "dataset = datasets.CelebA(\n",
    "    root=\"./data\",\n",
    "    split=\"train\",\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Initialize Models/Optimizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "adversarial_loss = nn.BCELoss().to(device)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Image Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, nrow=5):\n",
    "    grid = make_grid(images, nrow=nrow, normalize=True)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(np.transpose(grid.cpu(), (1,2,0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Training Loop with Real Time Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, _) in enumerate(tqdm(dataloader)):\n",
    "        \n",
    "        valid = torch.ones(imgs.size(0), 1, device=device)\n",
    "        fake = torch.zeros(imgs.size(0), 1, device=device)\n",
    "\n",
    "        real_imgs = imgs.to(device)\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn(imgs.size(0), latent_dim, device=device)\n",
    "        gen_imgs = generator(z)\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        G_losses.append(g_loss.item())\n",
    "        D_losses.append(d_loss.item())\n",
    "\n",
    "        if i % sample_interval == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"[Epoch {epoch}/{n_epochs}] [Batch {i}/{len(dataloader)}] [D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n",
    "            show_images(gen_imgs[:25])\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            real_imgs, _ = next(iter(dataloader))\n",
    "            real_imgs = denormalize(real_imgs)\n",
    "\n",
    "            z = torch.randn(real_imgs.size(0), opt.latent_dim).to(device)\n",
    "            gen_imgs = generator(z)\n",
    "            gen_imgs = denormalize(gen_imgs)\n",
    "\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "            axs[0].imshow(make_grid(real_imgs[:25], nrow=5).permute(1, 2, 0).cpu())\n",
    "            axs[0].set_title(f'Real CelebA Faces (Epoch {epoch})')\n",
    "            axs[0].axis('off')\n",
    "\n",
    "            axs[1].imshow(make_grid(gen_imgs[:25], nrow=5).permute(1, 2, 0).detach().cpu())\n",
    "            axs[1].set_title(f'Generated Faces (Epoch {epoch})')\n",
    "            axs[1].axis('off')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(25, opt.latent_dim).to(device)\n",
    "        gen_imgs = generator(z)\n",
    "        gen_imgs = denormalize(gen_imgs)\n",
    "        save_image(gen_imgs, f\"progress_images/epoch_{epoch:03d}.png\", nrow=5, normalize=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Loss Plot Post Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(G_losses, label=\"Generator Loss\")\n",
    "plt.plot(D_losses, label=\"Discriminator Loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"GAN Losses\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Faces Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# Load saved images\n",
    "image_files = sorted(glob.glob('progress_images/epoch_*.png'))\n",
    "\n",
    "frames = []\n",
    "for filename in image_files:\n",
    "    img = Image.open(filename)\n",
    "    frames.append(img)\n",
    "\n",
    "# Create animation\n",
    "frames[0].save('gan_training_progress.gif',\n",
    "               format='GIF',\n",
    "               append_images=frames[1:],\n",
    "               save_all=True,\n",
    "               duration=300,  # ms per frame\n",
    "               loop=0)\n",
    "\n",
    "# Display animation\n",
    "from IPython.display import Image as IPyImage\n",
    "IPyImage(open('gan_training_progress.gif', 'rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Generation of New Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(25, latent_dim, device=device)\n",
    "gen_imgs = generator(z)\n",
    "show_images(gen_imgs, nrow=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
