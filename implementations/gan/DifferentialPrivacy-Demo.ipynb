{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from opacus import PrivacyEngine\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        sample_input = torch.zeros(1, 1, 28, 28)\n",
    "        sample_output = self.features(sample_input)\n",
    "        num_features = sample_output.shape[1]\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 9852248.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 673121.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 5383139.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 25640011.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Define Modified Dataset and Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_removed = Subset(train_dataset, list(range(1, len(train_dataset))))\n",
    "\n",
    "train_loader_full = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "train_loader_removed = DataLoader(train_dataset_removed, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Define Model Training and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, epsilon, delta=1e-5, epochs=1):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    privacy_engine = PrivacyEngine()\n",
    "    model, optimizer, dataloader = privacy_engine.make_private(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=dataloader,\n",
    "        noise_multiplier=1.0,\n",
    "        max_grad_norm=1.0,\n",
    "    )\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model\n",
    "    \n",
    "def get_predictions(model, dataloader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for data, _ in dataloader:\n",
    "            output = model(data)\n",
    "            preds.append(output.softmax(dim=1).cpu().numpy())\n",
    "    return np.vstack(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyber1/.local/lib/python3.10/site-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "/home/cyber1/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1113: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_full = SimpleCNN()\n",
    "model_full = train(model_full, train_loader_full, epsilon=1.0)\n",
    "\n",
    "model_removed = SimpleCNN()\n",
    "model_removed = train(model_removed, train_loader_removed, epsilon=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Comparison of Outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference in predictions: 0.020119\n",
      "Full Prediction Mean: [[1.16137744e-09 1.09216256e-16 1.58304394e-11 ... 9.99998808e-01\n",
      "  2.88962582e-12 1.96775673e-07]\n",
      " [1.26322730e-09 2.23739707e-10 9.99986053e-01 ... 5.85302076e-22\n",
      "  9.58533633e-07 1.87259794e-18]\n",
      " [8.71668224e-11 9.99991655e-01 1.14783165e-06 ... 8.02043473e-07\n",
      "  4.28312248e-08 1.01641922e-08]\n",
      " ...\n",
      " [1.72753259e-15 3.54952802e-13 3.81870506e-14 ... 2.70993716e-08\n",
      "  3.41880835e-08 3.72739196e-05]\n",
      " [2.78639112e-09 5.40264264e-05 1.64589253e-09 ... 5.71252867e-09\n",
      "  2.42986381e-01 6.50359055e-08]\n",
      " [1.76302428e-11 1.33886705e-21 1.27881628e-06 ... 1.98587529e-24\n",
      "  1.26293968e-13 1.79071844e-16]]\n",
      "Removed Prediction Mean: [[6.7381331e-12 7.2091879e-16 5.1216786e-14 ... 9.9999976e-01\n",
      "  9.4268820e-13 2.1180117e-07]\n",
      " [3.6349634e-04 8.4612948e-13 9.9940252e-01 ... 3.4940552e-20\n",
      "  1.1668764e-06 4.6668739e-17]\n",
      " [8.3997147e-09 9.9998653e-01 2.5193992e-06 ... 3.8106460e-08\n",
      "  6.1010264e-06 7.7801104e-08]\n",
      " ...\n",
      " [3.4553022e-14 3.9091008e-11 3.1011467e-12 ... 2.9929570e-10\n",
      "  4.3403548e-07 2.3859539e-03]\n",
      " [4.7478676e-05 8.7682530e-04 1.5797980e-08 ... 1.0131000e-07\n",
      "  9.3288589e-01 1.2967612e-05]\n",
      " [1.6610752e-08 2.8421049e-21 7.2480959e-09 ... 9.2791502e-26\n",
      "  6.3769308e-13 8.7984007e-19]]\n"
     ]
    }
   ],
   "source": [
    "preds_full = get_predictions(model_full, test_loader)\n",
    "preds_removed = get_predictions(model_removed, test_loader)\n",
    "\n",
    "# Compute average absolute difference in predictions\n",
    "#Show that the difference is negligible \n",
    "difference = np.abs(preds_full - preds_removed).mean()\n",
    "print(f\"Average difference in predictions: {difference:.6f}\")\n",
    "print(f\"Full Prediction Mean: {preds_full}\")\n",
    "print(f\"Removed Prediction Mean: {preds_removed}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
