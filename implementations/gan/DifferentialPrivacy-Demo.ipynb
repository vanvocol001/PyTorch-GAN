{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dependencies and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision opacus\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from opacus import PrivacyEngine\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('.', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('.', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        \n",
    "        # Dynamically determine the size\n",
    "        sample_input = torch.zeros(1, 1, 28, 28)\n",
    "        sample_output = self.features(sample_input)\n",
    "        num_features = sample_output.shape[1]\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Define Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    for epoch in range(1, 6):\n",
    "        total_loss = 0\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run Standard Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_standard = SimpleCNN().to(device)\n",
    "optimizer_standard = optim.Adam(model_standard.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Training standard model...\")\n",
    "train(model_standard, train_loader, optimizer_standard, criterion, device)\n",
    "accuracy_standard = test(model_standard, test_loader, device)\n",
    "print(f\"Standard Model Accuracy: {accuracy_standard:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Run Differential Privacy Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dp = SimpleCNN().to(device)\n",
    "optimizer_dp = optim.Adam(model_dp.parameters(), lr=1e-4)\n",
    "privacy_engine = PrivacyEngine()\n",
    "\n",
    "model_dp, optimizer_dp, train_loader_dp = privacy_engine.make_private(\n",
    "    module=model_dp,\n",
    "    optimizer=optimizer_dp,\n",
    "    data_loader=train_loader,\n",
    "    noise_multiplier=1.0,  # Higher noise = more privacy\n",
    "    max_grad_norm=1.0,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training DP model...\")\n",
    "train(model_dp, train_loader_dp, optimizer_dp, criterion, device)\n",
    "accuracy_dp = test(model_dp, test_loader, device)\n",
    "print(f\"DP Model Accuracy: {accuracy_dp:.2f}%\")\n",
    "print(f\"DP Model is using (ε = {privacy_engine.get_epsilon(1e-5):.2f}, δ = 1e-5)\")\n",
    "epsilon = privacy_engine.get_epsilon(1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Compare the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Standard Model', 'DP Model']\n",
    "accuracies = [accuracy_standard, accuracy_dp]\n",
    "\n",
    "plt.bar(labels, accuracies, color=['blue', 'green'])\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title(f'DP ε = {epsilon:.2f}, δ = 1e-5')\n",
    "plt.ylim(0, 100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Compare Additional Noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mia\n",
    "import matplotlib.pyplot as plt\n",
    "from opacus import PrivacyEngine\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "noise_levels = [0.5, 1.0, 2.0, 4.0]\n",
    "epsilons = []\n",
    "accuracies = []\n",
    "mia_attack_success_rates = []\n",
    "generalization_gaps = []\n",
    "\n",
    "def basic_mia_attack(model, loader, device):\n",
    "    model.eval()\n",
    "    confidences = []\n",
    "    for data, _ in loader:\n",
    "        data = data.to(device)\n",
    "        outputs = model(data)\n",
    "        confidence = torch.max(torch.softmax(outputs, dim=1), dim=1)[0]\n",
    "        confidences.extend(confidence.cpu().detach().numpy())\n",
    "    # Simple heuristic: higher confidence = more likely to be training data\n",
    "    return np.mean(confidences)\n",
    "\n",
    "for noise_multiplier in tqdm(noise_levels):\n",
    "    model_dp = SimpleCNN().to(device)\n",
    "    optimizer_dp = optim.Adam(model_dp.parameters(), lr=1e-4)\n",
    "\n",
    "    privacy_engine = PrivacyEngine()\n",
    "    model_dp, optimizer_dp, train_loader_dp = privacy_engine.make_private(\n",
    "        module=model_dp,\n",
    "        optimizer=optimizer_dp,\n",
    "        data_loader=train_loader,\n",
    "        noise_multiplier=noise_multiplier,\n",
    "        max_grad_norm=1.0,\n",
    "    )\n",
    "\n",
    "    # Train DP model (fewer epochs for speed)\n",
    "    train(model_dp, train_loader_dp, optimizer_dp, criterion, device)\n",
    "\n",
    "    train_accuracy = test(model_dp, train_loader, device)\n",
    "    test_accuracy = test(model_dp, test_loader, device)\n",
    "    epsilon = privacy_engine.get_epsilon(1e-5)\n",
    "\n",
    "    generalization_gap = train_accuracy - test_accuracy\n",
    "    mia_score = basic_mia_attack(model_dp, train_loader, device)\n",
    "\n",
    "    accuracies.append(test_accuracy)\n",
    "    epsilons.append(epsilon)\n",
    "    generalization_gaps.append(generalization_gap)\n",
    "    mia_attack_success_rates.append(mia_score)\n",
    "\n",
    "# Plot privacy-utility trade-off\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epsilons, accuracies, marker='o')\n",
    "plt.xlabel(\"Privacy Loss (ε)\")\n",
    "plt.ylabel(\"Test Accuracy (%)\")\n",
    "plt.title(\"Privacy-Utility Trade-off\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Generalization Gap vs ε\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epsilons, generalization_gaps, marker='s', color='orange')\n",
    "plt.xlabel(\"Privacy Loss (ε)\")\n",
    "plt.ylabel(\"Generalization Gap (Train Acc - Test Acc)\")\n",
    "plt.title(\"Generalization Gap vs Privacy\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# MIA Attack Success vs ε\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epsilons, mia_attack_success_rates, marker='^', color='red')\n",
    "plt.xlabel(\"Privacy Loss (ε)\")\n",
    "plt.ylabel(\"Average Confidence on Training Data\")\n",
    "plt.title(\"MIA Attack Proxy vs Privacy\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
